The Bar Chart Race as a Data Visualization Tool
==============================

* ### [**Bar Chart Race as a Data Visualization Tool:**](https://github.com/fabioolivei/Fabio_Olivei_Data_Sciense/blob/main/The%20Bar%20Chart%20Race%20as%20a%20Data%20Visualization%20Tool/notebooks/O_Bar_Chart_Race_como_Ferramenta_de_Visualiza%C3%A7%C3%A3o_de_Dados%20(1).ipynb)

<div align="center">

![Descrição do GIF](https://github.com/fabioolivei/Fabio_Olivei_Data_Sciense/blob/main/COVID-19%20in%20Brazil%20and%20the%20world/reports/figures/evolu%C3%A7%C3%A3o_covid.gif)

</div>

**Situation:** The use of bar chart races has become increasingly popular in data visualization, particularly for showcasing the evolution of values over time. These dynamic charts offer a compelling and accessible way to present data changes, making it easier for audiences to grasp complex information quickly.

**Task:** Our objective was to leverage the bar chart race as a data visualization tool to effectively communicate changes in data over time. This involved selecting the appropriate software or programming language for creating the chart and ensuring the visualization clearly conveyed the intended insights.

**Action:** To accomplish this, we explored various methods for plotting a bar chart race, focusing on the following steps:
- Investigated the capabilities of open-source tools like Python and R for data visualization, recognizing their flexibility and wide support for generating dynamic charts.
- Decided to utilize Python for its extensive libraries (such as Matplotlib, Pandas, and Bar Chart Race) that facilitate the creation of bar chart races. This choice was motivated by Python's accessibility and the availability of tutorials and community support.
- Experimented with Gemini, a tool designed to assist in creating dynamic and interactive charts, in conjunction with ChatGPT. This combination allowed for a more streamlined process in chart creation, from data processing to visualization.

**Result:** By utilizing Python and exploring the functionalities of Gemini and ChatGPT, we successfully created a dynamic bar chart race that illustrates the evolution of data over time. This visualization tool proved to be an effective way to present data, offering clear and engaging insights into how values change over a period. The process highlighted the importance of selecting the right tools for data visualization tasks and demonstrated the potential of combining different technologies to enhance the clarity and impact of data presentations.

Project Organization
------------

    ├── LICENSE
    ├── Makefile           <- Makefile with commands like `make data` or `make train`
    ├── README.md          <- The top-level README for developers using this project.
    ├── data
    │   ├── external       <- Data from third party sources.
    │   ├── interim        <- Intermediate data that has been transformed.
    │   ├── processed      <- The final, canonical data sets for modeling.
    │   └── raw            <- The original, immutable data dump.
    │
    ├── docs               <- A default Sphinx project; see sphinx-doc.org for details
    │
    ├── models             <- Trained and serialized models, model predictions, or model summaries
    │
    ├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
    │                         the creator's initials, and a short `-` delimited description, e.g.
    │                         `1.0-jqp-initial-data-exploration`.
    │
    ├── references         <- Data dictionaries, manuals, and all other explanatory materials.
    │
    ├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    │   └── figures        <- Generated graphics and figures to be used in reporting
    │
    ├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    │                         generated with `pip freeze > requirements.txt`
    │
    ├── setup.py           <- makes project pip installable (pip install -e .) so src can be imported
    ├── src                <- Source code for use in this project.
    │   ├── __init__.py    <- Makes src a Python module
    │   │
    │   ├── data           <- Scripts to download or generate data
    │   │   └── make_dataset.py
    │   │
    │   ├── features       <- Scripts to turn raw data into features for modeling
    │   │   └── build_features.py
    │   │
    │   ├── models         <- Scripts to train models and then use trained models to make
    │   │   │                 predictions
    │   │   ├── predict_model.py
    │   │   └── train_model.py
    │   │
    │   └── visualization  <- Scripts to create exploratory and results oriented visualizations
    │       └── visualize.py
    │
    └── tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io


--------

<p><small>Project based on the <a target="_blank" href="https://drivendata.github.io/cookiecutter-data-science/">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>
